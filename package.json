{
  "name": "llm-distillery",
  "version": "1.0.2",
  "description": "Use LLMs to run map-reduce summarization tasks on large documents until a target token size is met.",
  "main": "llm-distillery.js",
  "type": "module",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [
    "text-distillation",
    "text-summarization",
    "text-compression",
    "token-management",
    "llm-distillery",
    "large-language-model",
    "LLM",
    "semantic-chunking",
    "text-processing",
    "AI-text-reduction",
    "openai-api",
    "tokenization"
  ],
  "author": "",
  "license": "ISC",
  "dependencies": {
    "@xenova/transformers": "^2.17.1",
    "fs": "^0.0.1-security",
    "openai": "^4.45.0",
    "semantic-chunking": "^1.1.0"
  }
}
